# Dataset: Iris 
# URL: https://www.kaggle.com/uciml/iris/data
# Modification: for each species, setosa is encoded to 0, versicolor is encoded to 1, and virginica samples were removed.
# Split: for each species, first 25 samples were included in train.csv, and last 25 samples were included in test.csv.
#
# Columns used as features 
features: 
  - sepal_length
  # - sepal_width
  # - petal_length
  # - petal_width 
#
# Column used as the target
target: species


# Dataset: Kaggle Titanic
# URL: https://www.kaggle.com/c/titanic/data
#
# Columns used as features 
# features:
#   - Pclass # The passenger's ticket class
#   - Parch # # of parents / children aboard the Titanic
#
# Columns used as features 
# target: Survived

model:
  =: sklearn.linear_model.LogisticRegression
  C: 1.23456
  max_iter: 987
  random_state: 42

PIPELINES:
  __default__:
    =: pipelinex.FlexiblePipeline
    module: # Optionally specify the default Python module so you can omit the module name to which functions belongs
    decorator: # Optionally specify function decorator(s) to apply to each node
    nodes:
      - inputs: ["params:model", train_df, "params:features", "params:target"]
        func: {{ cookiecutter.python_package }}.nodes.data_science.train_model
        outputs: model

      - inputs: [model, test_df, "params:features"]
        func: {{ cookiecutter.python_package }}.nodes.data_science.run_inference
        outputs: pred_df

      - inputs: [model, train_df, "params:features", "params:target"]
        func: {{ cookiecutter.python_package }}.nodes.data_science.evaluate_model
        outputs: score

RUN_CONFIG:
  pipeline_name: __default__
  runner: SequentialRunner # Set to "ParallelRunner" to run in parallel
  only_missing: False # Set True to run only missing nodes
  tags: # None
  node_names: # None
  from_nodes: # None
  to_nodes: # None
  from_inputs: # None
  load_versions: # None
